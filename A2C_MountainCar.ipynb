{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roadmap for this notebook:\n",
    "\n",
    "#### A) Discrete Mountaincar, to directly compare to DQN on this benchmark.\n",
    "\n",
    "1. A basic actor-critic, with the appropriate losses.\n",
    "2. A parallised version, in threading mode. Reqs accumulating losses, and the threading version.\n",
    "3. A multiprocessing version, where the workers work in parallel. Reqs communicating variables across memory spaces.\n",
    "4. Entropy loss.\n",
    "5. Normalization of losses, etc.?\n",
    "6. Joint basic network for actions and values? Use additive loss?\n",
    "\n",
    "#### B) Continuous Mountaincar\n",
    "\n",
    "#### C) Atari?\n",
    "\n",
    "#### D) Generalised advantage estimation?\n",
    "\n",
    "\n",
    "### Questions:\n",
    "\n",
    "1. loss values will be quite correlated, certainly wrt experience replay. How does this affect the algorithm?\n",
    "2. How would DQN perform vs this if experience replay doesn't happen every step?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A1) AC implementation on the discrete Mountain Car\n",
    "\n",
    "We'll do an implementation with separate value and policy networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\arne_\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\arne_\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\arne_\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\arne_\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\arne_\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\arne_\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import gym\n",
    "import time\n",
    "from collections import deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras import models \n",
    "from keras import layers\n",
    "import keras.backend as kb\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colors as c\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actor_loss(y_actual, y_pred):\n",
    "    \"\"\"\n",
    "    My guess: y_pred is pi(a|s),\n",
    "              y_actual will be (G_estim - V(S_t)) * 1_{a = A_t}\n",
    "    We want: - log(pi(A_t|s)) (G_estim - V(S_t)), note that we only select one action.\n",
    "    \"\"\"\n",
    "    return - kb.log(y_pred + 1e-10) * kb.stop_gradient(y_actual) # This is automatically cast to a scalar?\n",
    "\n",
    "class ACAgent_discrete():\n",
    "    \n",
    "    def __init__(self, env, track_V = False, learning_rate = 0.001):\n",
    "        \n",
    "        # Hyperparameters for the algorithm:\n",
    "        self.epsilon = .9       # Exploration rate. \n",
    "        self.epsilon_decay = .95 # Decay of the exploration rate, multiplied with epsilon every training episode.\n",
    "        self.epsilon_min = .1                   # Minimal exploration rate.\n",
    "        self.lr = learning_rate                 # Learning Rate.\n",
    "        self.gamma = .99                        # The discounting factor of the Markov Decision Process.\n",
    "    \n",
    "        # Environment specification:\n",
    "        self.env = env\n",
    "        self.num_actions = env.action_space.n\n",
    "        self.num_state_dim = env.observation_space.shape[0]\n",
    "        \n",
    "        # Q-Network and Policy Network specifications - 2 hidden layers with relu followed by, for the\n",
    "        #                                               Value network (\"The Critic\"): a linear layer\n",
    "        #                                               Policy Network (\"The Actor\"): a softmax layer\n",
    "        self.num_nodes_layer1 = 24          # The number of nodes in the first hidden layer of the network.\n",
    "        self.num_nodes_layer2 = 48          # The number of nodes in the second hidden layer of the network.\n",
    "        self.critic = self.init_critic()\n",
    "        self.target_critic = self.init_critic() # Fixed targets for the network updates.\n",
    "        self.target_critic.set_weights(self.critic.get_weights())\n",
    "        self.actor = self.init_actor()\n",
    "         \n",
    "        # Metrics to evaluate the agent - TODO\n",
    "        self.training_epis = 0              # Number of training iterations so far.\n",
    "        self.num_steps = []                 # Number of time steps needed to complete the episode, for each episode.\n",
    "        self.values = []                    # Total reward acrued for every episode.\n",
    "        self.max_X_list = []                # A list keeping track of the maximal x position in every training episode.\n",
    "        self.track_V = track_V              # A boolean indicating whether the agent keeps track of the V-values at 2 states over all episodes.\n",
    "        self.xstart_vpos = []               # List of V-estimates in x = -0.5 (start position) and v = 0.01 over the training iterations.\n",
    "        self.xstart_vneg = []               # List of V-estimates in x = -0.5 (start position) and v = -0.01 over the training iterations.\n",
    "\n",
    "        \n",
    "    def init_critic(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units = self.num_nodes_layer1, activation = 'relu', input_dim = self.num_state_dim))\n",
    "        model.add(Dense(units = self.num_nodes_layer2, activation = 'relu'))\n",
    "        model.add(Dense(1, activation = 'linear'))\n",
    "        model.compile(loss = 'mse', \n",
    "                      optimizer = Adam(lr = self.lr))\n",
    "        return model\n",
    "    \n",
    "    def init_actor(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units = self.num_nodes_layer1, activation = 'relu', input_dim = self.num_state_dim))\n",
    "        model.add(Dense(units = self.num_nodes_layer2, activation = 'relu'))\n",
    "        model.add(Dense(self.num_actions, activation = 'softmax'))\n",
    "        model.compile(loss = actor_loss, \n",
    "                      optimizer = Adam(lr = self.lr))\n",
    "        return model\n",
    "    \n",
    "#     def learn_test(self, state, verbose = False):\n",
    "#         \"\"\"\n",
    "#         State needs to be of shape [1, state_dim]\n",
    "#         \"\"\"\n",
    "#         p = self.actor.predict(state)[0]\n",
    "#         action = np.random.choice(self.num_actions, p = self.actor.predict(state)[0])\n",
    "#         next_state, reward, done, _ = self.env.step(action)\n",
    "#         next_state = np.reshape(next_state, [1, self.num_state_dim])\n",
    "        \n",
    "#         target = self.critic.predict(state)\n",
    "#         next_state_target = self.target_critic.predict(next_state)\n",
    "#         TD = np.array([0. for i in range(self.num_actions)]).reshape([1, self.num_actions])\n",
    "#         if verbose:\n",
    "#             print(f\"Initial Critic estimate for the initial state: {target}\")\n",
    "#             print(f\"Initial Actor estimate: {p}\")\n",
    "\n",
    "#         if done:\n",
    "#             TD[0,action] = reward - target[0]\n",
    "#             target[0] = reward\n",
    "#         else:\n",
    "#             TD[0,action] = reward + self.gamma * next_state_target[0] - target[0] # Change to Sarsa?\n",
    "#             target[0] = reward + self.gamma * next_state_target[0]\n",
    "            \n",
    "#         self.critic.fit(state, target, epochs = 1, verbose = 0) # keras requires multidimensional targets. The ones corresponding to the actions not taken cancel out.\n",
    "#         self.actor.fit(state, TD, epochs = 1, verbose = 0)\n",
    "#         if verbose:\n",
    "#             print(f\"After learning: Critic estimate at initial state: {self.critic.predict(state)}, target: {target}, action: {action}.\")\n",
    "#             print(f\"TD: {TD}, updated actor estimate: {self.actor.predict(state)}.\")\n",
    "#             print(\"Note that if TD is positive, then the optimization objective should increase the chance of the action chosen. And vice versa.\")\n",
    "        \n",
    "#         return reward, next_state, done\n",
    "        \n",
    "#     def test(self):\n",
    "#         state = np.reshape(env.reset(), [1, self.num_state_dim])\n",
    "#         self.learn_test(state)\n",
    "        \n",
    "    def learn(self, state, action, reward, next_state, done, verbose = False):\n",
    "        # Maybe more efficient if not copying all these variables? But perhaps negligible wrt computations inside. \n",
    "        \n",
    "        target = self.critic.predict(state)\n",
    "        next_state_target = self.target_critic.predict(next_state)\n",
    "        TD = np.array([0. for i in range(self.num_actions)]).reshape([1, self.num_actions])\n",
    "        if verbose:\n",
    "            print(f\"Initial Critic estimate for the initial state: {target}\")\n",
    "            print(f\"Initial Actor estimate: {p}\")\n",
    "\n",
    "        if done:\n",
    "            TD[0,action] = reward - target[0]\n",
    "            target[0] = reward\n",
    "        else:\n",
    "            TD[0,action] = reward + self.gamma * next_state_target[0] - target[0] # Change to Sarsa?\n",
    "            target[0] = reward + self.gamma * next_state_target[0]\n",
    "            \n",
    "        self.critic.fit(state, target, epochs = 1, verbose = 0) # keras requires multidimensional targets. The ones corresponding to the actions not taken cancel out.\n",
    "        self.actor.fit(state, TD, epochs = 1, verbose = 0)\n",
    "        if verbose:\n",
    "            print(f\"After learning: Critic estimate at initial state: {self.critic.predict(state)}, target: {target}, action: {action}.\")\n",
    "            print(f\"TD: {TD}, updated actor estimate: {self.actor.predict(state)}.\")\n",
    "            print(\"Note that if TD is positive, then the optimization objective should increase the chance of the action chosen. And vice versa.\")\n",
    "        \n",
    "        \n",
    "    def learn_mepis(self, num_epis, verbose = True):\n",
    "        \n",
    "        end_it = self.training_epis + num_epis # The total amount of episodes the agent will have trained on after this function finishes.\n",
    "    \n",
    "        for epis in range(num_epis):\n",
    "            epis_time = time.time()\n",
    "            state = np.reshape(self.env.reset(), [1, self.num_state_dim])\n",
    "            self.values.append(0)\n",
    "            max_X = state[0,0]\n",
    "            for t in range(201):\n",
    "                \n",
    "                # Sample action:\n",
    "                action = np.random.choice(self.num_actions, p = self.actor.predict(state)[0])\n",
    "                \n",
    "                # Sample environment:\n",
    "                next_state, reward, done, _ = self.env.step(action)\n",
    "                next_state = np.reshape(next_state, [1, self.num_state_dim])\n",
    "                \n",
    "                # Update actor and critic:\n",
    "                self.learn(state, action, reward, next_state, done)\n",
    "                state = next_state\n",
    "                                \n",
    "                # Updates for some of the evaluation metrics:\n",
    "                self.values[-1] += (self.gamma ** t) * reward\n",
    "                if state[0,0] > max_X:\n",
    "                    max_X = state[0,0]\n",
    "                    \n",
    "                if done:\n",
    "                    self.num_steps.append(t+1)\n",
    "                    self.max_X_list.append(max_X)\n",
    "                    break\n",
    "                    \n",
    "            self.target_critic.set_weights(self.critic.get_weights())\n",
    "            \n",
    "            # Updates for some of the evaluation metrics:\n",
    "            self.training_epis += 1\n",
    "            if self.track_V:\n",
    "                self.track_V_fct()\n",
    "                \n",
    "            # Some diagnostic information to be printed:\n",
    "            if verbose:\n",
    "                print(f\"\\r{self.training_epis}/{end_it} episodes. Episode time: {time.time() - epis_time}. Max x: {max_X}, t = {self.num_steps[-1]}.\", end = '')\n",
    "            \n",
    "            # Update the exploration rate:\n",
    "            if self.epsilon > self.epsilon_min:\n",
    "                self.epsilon *= self.epsilon_decay\n",
    "                \n",
    "    def track_V_fct(self):\n",
    "        \"\"\"\n",
    "        Track the V values over the different episodes at [-0.5, 0.01] and [-0.5, -0.01].\n",
    "        \"\"\"\n",
    "        self.xstart_vpos.append( self.critic.predict(np.array([-0.5, 0.01]).reshape([1,2])))\n",
    "        self.xstart_vneg.append( self.critic.predict(np.array([-0.5, -0.01]).reshape([1,2])))\n",
    "        \n",
    "    def plot_max_X(self, start_it = 0):\n",
    "        \"\"\"\n",
    "        Plots the maximal x-value that was attained during the different training episodes.\n",
    "        \"\"\"\n",
    "        fig = plt.figure()\n",
    "        grid = np.arange(start_it, self.training_epis)\n",
    "        plt.plot(grid, self.max_X_list[start_it:])\n",
    "        plt.title(\"Maximum x-value reached per episode\")\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_num_steps(self, start_it = 0):\n",
    "        \"\"\"\n",
    "        Plots the number of steps needed to complete the episodes during the different training episodes.\n",
    "        \"\"\"\n",
    "        fig = plt.figure()\n",
    "        grid = np.arange(start_it, self.training_epis)\n",
    "        plt.plot(grid, self.num_steps[start_it:])\n",
    "        plt.title(\"Number of steps needed to complete the episode (max = 200)\")\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('MountainCar-v0')\n",
    "agent = ACAgent_discrete(env, track_V = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1020/1020 episodes. Episode time: 0.9160935878753662. Max x: -0.1499382767519785, t = 200.."
     ]
    }
   ],
   "source": [
    "agent.learn_mepis(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent.plot_max_X()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`threading` versus `multiprocessing`?\n",
    "\n",
    "[link](https://realpython.com/intro-to-python-threading/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A2) Threading version of A3C on Discrete Mountaincar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part will restructure some code of the previous section, by splitting it into:\n",
    "1. A class AC_Network that builds an Actor-Critic model.\n",
    "2. Worker classes that will instantiate local AC-models, create rollouts of the environment, and apply learning to the global network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actor_loss(y_actual, y_pred):\n",
    "    \"\"\"\n",
    "    My guess: y_pred is pi(a|s),\n",
    "              y_actual will be (G_estim - V(S_t)) * 1_{a = A_t}\n",
    "    We want: - log(pi(A_t|s)) (G_estim - V(S_t)), note that we only select one action.\n",
    "    \"\"\"\n",
    "    return - kb.log(y_pred + 1e-10) * kb.stop_gradient(y_actual) # This is automatically cast to a scalar?\n",
    "\n",
    "class AC_Network():\n",
    "    def __init__(self, num_state_dim ,num_actions, lr):\n",
    "        self.num_state_dim = num_state_dim  # The dimension of the state space.\n",
    "        self.num_actions = num_actions      # The number of actions.\n",
    "        self.lr = lr                        # The learning rate of the network optimiser\n",
    "        \n",
    "        # Q-Network and Policy Network specifications - 2 hidden layers with relu followed by, for the\n",
    "        #                                               Value network (\"The Critic\"): a linear layer\n",
    "        #                                               Policy Network (\"The Actor\"): a softmax layer\n",
    "        # Note: At the moment, we do not keep track of a separate Target Network. \n",
    "        #       As updates are only applied every couple of steps, it is kept fixed for the duration in between.\n",
    "        self.num_nodes_layer1 = 24          # The number of nodes in the first hidden layer of the network.\n",
    "        self.num_nodes_layer2 = 48          # The number of nodes in the second hidden layer of the network.\n",
    "        self.critic = self.init_critic()\n",
    "        self.actor = self.init_actor()\n",
    "    \n",
    "    def init_critic(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units = self.num_nodes_layer1, activation = 'relu', input_dim = self.num_state_dim))\n",
    "        model.add(Dense(units = self.num_nodes_layer2, activation = 'relu'))\n",
    "        model.add(Dense(1, activation = 'linear'))\n",
    "        model.compile(loss = 'mse', \n",
    "                      optimizer = Adam(lr = self.lr))\n",
    "        return model\n",
    "    \n",
    "    def init_actor(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units = self.num_nodes_layer1, activation = 'relu', input_dim = self.num_state_dim))\n",
    "        model.add(Dense(units = self.num_nodes_layer2, activation = 'relu'))\n",
    "        model.add(Dense(self.num_actions, activation = 'softmax'))\n",
    "        model.compile(loss = actor_loss, \n",
    "                      optimizer = Adam(lr = self.lr))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Worker():\n",
    "    \n",
    "    def __init__(self, env, worker_name, epsilon = .95, epsilon_decay = .95, learning_rate = .001, t_update = 31, track_V = False):\n",
    "        # Hyperparameters for the algorithm:\n",
    "        self.epsilon = epsilon                  # Exploration rate. \n",
    "        self.epsilon_decay = epsilon_decay      # Decay of the exploration rate, multiplied with epsilon every training episode.\n",
    "        self.epsilon_min = .1                   # Minimal exploration rate.\n",
    "        self.lr = learning_rate                 # Learning Rate.\n",
    "        self.gamma = .99                        # The discounting factor of the Markov Decision Process\n",
    "        self.t_update = t_update                # Number of steps before updating the global network\n",
    "        \n",
    "        # Environment specification:\n",
    "        self.env = env\n",
    "        self.num_state_dim = env.observation_space.shape[0]\n",
    "        self.num_actions = env.action_space.n\n",
    "        \n",
    "        # Actor and Critic models:\n",
    "        self.network = AC_Network(self.num_state_dim, self.num_actions, self.lr)\n",
    "        \n",
    "        # Some trackers:\n",
    "        self.name = worker_name\n",
    "        self.num_steps = 0                  # Total number of steps taken.\n",
    "        self.num_steps_to_completion = []   # Number of time steps needed to complete the episode, for each episode.\n",
    "        self.max_X_list = []                # A list keeping track of the maximal x position in every training episode.\n",
    "\n",
    "        # TODO - to implement\n",
    "        self.values = []                    # Total reward acrued for every episode.\n",
    "        self.track_V = track_V              # A boolean indicating whether the agent keeps track of the V-values at 2 states over all episodes.\n",
    "        self.xstart_vpos = []               # List of V-estimates in x = -0.5 (start position) and v = 0.01 over the training iterations.\n",
    "        self.xstart_vneg = []               # List of V-estimates in x = -0.5 (start position) and v = -0.01 over the training iterations.\n",
    "\n",
    "    def update_network_weights(self, critic_weights, actor_weights):\n",
    "        self.network.critic.set_weights(self.critic_weights)\n",
    "        self.actor.critic.set_weights(self.actor_weights)\n",
    "        # TODO: update target weights.\n",
    "                  \n",
    "    def work(self, num_steps):\n",
    "        final_num_steps = self.num_steps + num_steps # The number of steps that will have been taken after this function call.\n",
    "                \n",
    "        state = env.reset()\n",
    "        state = np.reshape(self.env.reset(), [1, self.num_state_dim])\n",
    "        rollout = {'states':[], 'actions': [], 'rewards': [], 'values': np.zeros([self.t_update + 1, 1]), 'done': []} # The [states], [actions], [rewards], [values] [done] before a network update gets performed.\n",
    "        rollout['states'].append(state)\n",
    "\n",
    "        t = 0\n",
    "        t_start = 0 # The startin index of the current rollout\n",
    "        while t < num_steps:           \n",
    "            # 1-Rollout\n",
    "            # Sample action:\n",
    "            action = np.random.choice(self.num_actions, p = self.network.actor.predict(state)[0])\n",
    "                \n",
    "            # Sample environment:\n",
    "            next_state, reward, done, _ = self.env.step(action)\n",
    "            next_state = np.reshape(next_state, [1, self.num_state_dim])\n",
    "            \n",
    "            rollout['states'].append(next_state)\n",
    "            rollout['actions'].append(action)\n",
    "            rollout['rewards'].append(reward)\n",
    "            rollout['done'].append(done)\n",
    "            \n",
    "            state = next_state\n",
    "            \n",
    "            # TODO - Compute number of steps per episode, max_X\n",
    "            \n",
    "            t += 1\n",
    "            # Update loop\n",
    "            if done or t % self.t_update == 0:\n",
    "                # 2-Discounted value computation \n",
    "                # First a dummy variable:\n",
    "                if not done: \n",
    "                    rollout['values'][-1, 0] = self.network.critic.predict(state)[0]\n",
    "                    # if done, then we keep 0. at the end\n",
    "                \n",
    "                for s in range(t - t_start):\n",
    "                    rollout['values'][-s - 2, 0] = rollout['rewards'][-s - 1] + self.gamma * rollout['values'][-s - 1, 0]\n",
    "                # So now the 'values' consists of the reverse of [V_{T+1}, r_T+ y V_{T+1}, r_{T-1} + y r_T + y^2 V_{T+1}, ... ] ('t - t_start + 1' values)\n",
    "                # There might be 0. in the beginning if the episode terminates before t_update is reached.\n",
    "                \n",
    "                # 3-Network update and copy, reset rollout, reset state\n",
    "                # Need one hot advantages for the actor, just the values for the critic.\n",
    "                n = len(rollout['states']) # Should be t - t_start + 1\n",
    "                rollout['states'] = np.array(rollout['states']).reshape([n, self.num_state_dim])\n",
    "                targets = self.network.critic.predict(rollout['states'])\n",
    "                advantages = np.zeros([n-1, self.num_actions])\n",
    "                ## TODO - ...\n",
    "                \n",
    "                if done: \n",
    "                    state = np.reshape(env.reset(), [1, self.num_state_dim])\n",
    "                rollout = {'states':[], 'actions': [], 'rewards': [], 'values': np.zeros([self.t_update + 1, 1]), 'done': []} # The [states], [actions], [rewards], [values] [done] before a network update gets performed.\n",
    "                rollout['states'].append(state)\n",
    "                t_start = t\n",
    "                if self.epsilon > self.epsilon_min:\n",
    "                    self.epsilon *= self.epsilon_decay\n",
    "            \n",
    "            \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to see how much time is spent in every thread?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('MountainCar-v0')\n",
    "worker = Worker(env, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 31\n",
      "[[-2.67843331e+01]\n",
      " [-2.60447809e+01]\n",
      " [-2.52977585e+01]\n",
      " [-2.45431904e+01]\n",
      " [-2.37810004e+01]\n",
      " [-2.30111115e+01]\n",
      " [-2.22334460e+01]\n",
      " [-2.14479252e+01]\n",
      " [-2.06544699e+01]\n",
      " [-1.98529999e+01]\n",
      " [-1.90434343e+01]\n",
      " [-1.82256912e+01]\n",
      " [-1.73996881e+01]\n",
      " [-1.65653415e+01]\n",
      " [-1.57225672e+01]\n",
      " [-1.48712800e+01]\n",
      " [-1.40113939e+01]\n",
      " [-1.31428221e+01]\n",
      " [-1.22654769e+01]\n",
      " [-1.13792696e+01]\n",
      " [-1.04841107e+01]\n",
      " [-9.57990979e+00]\n",
      " [-8.66657555e+00]\n",
      " [-7.74401571e+00]\n",
      " [-6.81213708e+00]\n",
      " [-5.87084553e+00]\n",
      " [-4.92004599e+00]\n",
      " [-3.95964242e+00]\n",
      " [-2.98953780e+00]\n",
      " [-2.00963414e+00]\n",
      " [-1.01983246e+00]\n",
      " [-2.00327896e-02]]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-2802e3602307>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mworker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-71-627f6c385162>\u001b[0m in \u001b[0;36mwork\u001b[1;34m(self, num_steps)\u001b[0m\n\u001b[0;32m     69\u001b[0m                 \u001b[1;31m# First a dummy variable:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m                     \u001b[0mrollout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'values'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcritic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m                     \u001b[1;31m# if done, then we keep 0. at the end\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'values'"
     ]
    }
   ],
   "source": [
    "worker.work(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A3C on the continuous MountainCar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(2,)\n",
      "Box(1,)\n",
      "[0.6  0.07]\n",
      "[-1.2  -0.07]\n",
      "[1.]\n",
      "[-1.]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('MountainCarContinuous-v0')\n",
    "print(env.observation_space)\n",
    "print(env.action_space)\n",
    "print(env.observation_space.high)\n",
    "print(env.observation_space.low)\n",
    "print(env.action_space.high)\n",
    "print(env.action_space.low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.51817812  0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(env.reset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_t = [0.29548127], r_t = -0.008730918306552931, s_t+1 : [-0.52446611 -0.01893768].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 0\n",
      "\n",
      "\n",
      "a_t = [1.2958299], r_t = -0.16791751405481958, s_t+1 : [-0.54189728 -0.01743117].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 1\n",
      "\n",
      "\n",
      "a_t = [-0.79970373], r_t = -0.06395260631247225, s_t+1 : [-0.56039084 -0.01849356].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 2\n",
      "\n",
      "\n",
      "a_t = [-0.2783974], r_t = -0.007750511189628499, s_t+1 : [-0.57902661 -0.01863577].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 3\n",
      "\n",
      "\n",
      "a_t = [-0.95881143], r_t = -0.09193193644071852, s_t+1 : [-0.59868681 -0.0196602 ].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 4\n",
      "\n",
      "\n",
      "a_t = [1.22178377], r_t = -0.14927555902765666, s_t+1 : [-0.6162886  -0.01760179].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 5\n",
      "\n",
      "\n",
      "a_t = [-0.62659309], r_t = -0.03926188967405608, s_t+1 : [-0.63414402 -0.01785543].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 6\n",
      "\n",
      "\n",
      "a_t = [0.81458557], r_t = -0.0663549645112884, s_t+1 : [-0.6499636  -0.01581957].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 7\n",
      "\n",
      "\n",
      "a_t = [-0.71101904], r_t = -0.05055480694134447, s_t+1 : [-0.6659245 -0.0159609].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 8\n",
      "\n",
      "\n",
      "a_t = [0.1576873], r_t = -0.00248652861226096, s_t+1 : [-0.68061357 -0.01468907].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 9\n",
      "\n",
      "\n",
      "a_t = [0.76824275], r_t = -0.059019693019567804, s_t+1 : [-0.69301573 -0.01240216].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 10\n",
      "\n",
      "\n",
      "a_t = [-0.78397131], r_t = -0.06146110188099457, s_t+1 : [-0.70537723 -0.01236149].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 11\n",
      "\n",
      "\n",
      "a_t = [1.0227627], r_t = -0.10460435428134102, s_t+1 : [-0.71494196 -0.00956473].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 12\n",
      "\n",
      "\n",
      "a_t = [0.20644668], r_t = -0.004262023311723457, s_t+1 : [-0.72283947 -0.00789751].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 13\n",
      "\n",
      "\n",
      "a_t = [-0.56285887], r_t = -0.031681010637556094, s_t+1 : [-0.73017437 -0.0073349 ].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 14\n",
      "\n",
      "\n",
      "a_t = [0.81701045], r_t = -0.0667506082038936, s_t+1 : [-0.73483172 -0.00465735].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 15\n",
      "\n",
      "\n",
      "a_t = [-0.7542025], r_t = -0.05688214093204912, s_t+1 : [-0.73914005 -0.00430833].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 16\n",
      "\n",
      "\n",
      "a_t = [0.69559751], r_t = -0.04838558981582536, s_t+1 : [-0.74089875 -0.0017587 ].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 17\n",
      "\n",
      "\n",
      "a_t = [-1.35781058], r_t = -0.18436495580979015, s_t+1 : [-0.7426407  -0.00174195].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 18\n",
      "\n",
      "\n",
      "a_t = [-1.27280724], r_t = -0.16200382590281667, s_t+1 : [-0.74435554 -0.00171484].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 19\n",
      "\n",
      "\n",
      "a_t = [-0.85669033], r_t = -0.07339183213454428, s_t+1 : [-0.74581814 -0.00146261].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 20\n",
      "\n",
      "\n",
      "a_t = [-0.74101057], r_t = -0.05490966603678513, s_t+1 : [-0.74684636 -0.00102821].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 21\n",
      "\n",
      "\n",
      "a_t = [-0.12286673], r_t = -0.0015096232968455602, s_t+1 : [-7.46506912e-01  3.39446778e-04].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 22\n",
      "\n",
      "\n",
      "a_t = [0.70080214], r_t = -0.049112364281786294, s_t+1 : [-0.7435663   0.00294061].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 23\n",
      "\n",
      "\n",
      "a_t = [0.01016285], r_t = -1.0328359960779113e-05, s_t+1 : [-0.73907784  0.00448846].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 24\n",
      "\n",
      "\n",
      "a_t = [1.2016693], r_t = -0.1444009113728955, s_t+1 : [-0.73158352  0.00749432].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 25\n",
      "\n",
      "\n",
      "a_t = [-0.20646726], r_t = -0.00426287304391078, s_t+1 : [-0.72293827  0.00864525].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 26\n",
      "\n",
      "\n",
      "a_t = [0.83885897], r_t = -0.07036843751890369, s_t+1 : [-0.71162722  0.01131105].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 27\n",
      "\n",
      "\n",
      "a_t = [-0.5806317], r_t = -0.03371331755076706, s_t+1 : [-0.69985051  0.01177671].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 28\n",
      "\n",
      "\n",
      "a_t = [-1.07024155], r_t = -0.11454169659607645, s_t+1 : [-0.68831266  0.01153786].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 29\n",
      "\n",
      "\n",
      "a_t = [-0.85420867], r_t = -0.07296724596295716, s_t+1 : [-0.67687043  0.01144223].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 30\n",
      "\n",
      "\n",
      "a_t = [0.00969483], r_t = -9.398972790299383e-06, s_t+1 : [-0.66430419  0.01256623].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 31\n",
      "\n",
      "\n",
      "a_t = [0.40458128], r_t = -0.016368601253960228, s_t+1 : [-0.65010686  0.01419733].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 32\n",
      "\n",
      "\n",
      "a_t = [-1.03844443], r_t = -0.10783668352995684, s_t+1 : [-0.63648333  0.01362353].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 33\n",
      "\n",
      "\n",
      "a_t = [0.44725819], r_t = -0.0200039889049698, s_t+1 : [-0.62135837  0.01512496].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 34\n",
      "\n",
      "\n",
      "a_t = [0.92462505], r_t = -0.08549314914040694, s_t+1 : [-0.60412374  0.01723463].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 35\n",
      "\n",
      "\n",
      "a_t = [0.69249621], r_t = -0.04795510045498502, s_t+1 : [-0.58525229  0.01887145].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 36\n",
      "\n",
      "\n",
      "a_t = [-1.84951917], r_t = -0.3420721153938085, s_t+1 : [-0.56742106  0.01783122].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 37\n",
      "\n",
      "\n",
      "a_t = [-0.63233235], r_t = -0.03998441964414542, s_t+1 : [-0.55021062  0.01721045].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 38\n",
      "\n",
      "\n",
      "a_t = [-1.22100017], r_t = -0.14908414094019826, s_t+1 : [-0.5343008   0.01590982].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 39\n",
      "\n",
      "\n",
      "a_t = [-0.9598671], r_t = -0.09213448473316588, s_t+1 : [-0.51975052  0.01455027].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 40\n",
      "\n",
      "\n",
      "a_t = [-0.58986051], r_t = -0.034793541769507906, s_t+1 : [-0.5061139   0.01363662].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 41\n",
      "\n",
      "\n",
      "a_t = [2.22812861], r_t = -0.4964557091919661, s_t+1 : [-0.49110835  0.01500555].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 42\n",
      "\n",
      "\n",
      "a_t = [-0.73436146], r_t = -0.053928675110533376, s_t+1 : [-0.47744764  0.01366071].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 43\n",
      "\n",
      "\n",
      "a_t = [1.14187913], r_t = -0.1303887946474123, s_t+1 : [-0.46263196  0.01481568].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 44\n",
      "\n",
      "\n",
      "a_t = [0.43759257], r_t = -0.01914872545137699, s_t+1 : [-0.4476146   0.01501736].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 45\n",
      "\n",
      "\n",
      "a_t = [1.26544122], r_t = -0.16013414690794053, s_t+1 : [-0.43166219  0.01595241].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 46\n",
      "\n",
      "\n",
      "a_t = [-0.19481023], r_t = -0.0037951026751130903, s_t+1 : [-0.41668282  0.01497938].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 47\n",
      "\n",
      "\n",
      "a_t = [0.00169042], r_t = -2.857506090651317e-07, s_t+1 : [-0.4024891   0.01419372].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 48\n",
      "\n",
      "\n",
      "a_t = [-0.54043716], r_t = -0.02920723256610045, s_t+1 : [-0.3899945   0.01249459].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 49\n",
      "\n",
      "\n",
      "a_t = [1.48151878], r_t = -0.21948978994718496, s_t+1 : [-0.37697533  0.01301918].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 50\n",
      "\n",
      "\n",
      "a_t = [-0.3161685], r_t = -0.009996251749703351, s_t+1 : [-0.36549496  0.01148037].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 51\n",
      "\n",
      "\n",
      "a_t = [-0.24777043], r_t = -0.006139018743558393, s_t+1 : [-0.35552806  0.0099669 ].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 52\n",
      "\n",
      "\n",
      "a_t = [-0.60133578], r_t = -0.03616047172323376, s_t+1 : [-0.34767096  0.0078571 ].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 53\n",
      "\n",
      "\n",
      "a_t = [0.3109805], r_t = -0.009670887124015313, s_t+1 : [-0.34060644  0.00706452].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 54\n",
      "\n",
      "\n",
      "a_t = [-1.5985444], r_t = -0.25553441853859865, s_t+1 : [-0.33634645  0.00425998].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 55\n",
      "\n",
      "\n",
      "a_t = [-1.32043103], r_t = -0.17435380996229227, s_t+1 : [-0.33491815  0.0014283 ].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 56\n",
      "\n",
      "\n",
      "a_t = [0.15565583], r_t = -0.0024228736297355596, s_t+1 : [-3.34597107e-01  3.21044787e-04].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 57\n",
      "\n",
      "\n",
      "a_t = [0.5268948], r_t = -0.02776181321546414, s_t+1 : [-3.34828491e-01 -2.31383369e-04].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 58\n",
      "\n",
      "\n",
      "a_t = [-0.30482228], r_t = -0.009291662337085073, s_t+1 : [-0.33685841 -0.00202992].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 59\n",
      "\n",
      "\n",
      "a_t = [-1.45853414], r_t = -0.21273218454778098, s_t+1 : [-0.34171677 -0.00485836].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 60\n",
      "\n",
      "\n",
      "a_t = [0.6221009], r_t = -0.038700953332162454, s_t+1 : [-0.3469394  -0.00522263].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 61\n",
      "\n",
      "\n",
      "a_t = [0.17312264], r_t = -0.002997144721454445, s_t+1 : [-0.35316614 -0.00622673].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 62\n",
      "\n",
      "\n",
      "a_t = [0.61551958], r_t = -0.037886434999739725, s_t+1 : [-0.35969286 -0.00652673].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 63\n",
      "\n",
      "\n",
      "a_t = [0.29752254], r_t = -0.0088519660592438, s_t+1 : [-0.36695366 -0.0072608 ].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 64\n",
      "\n",
      "\n",
      "a_t = [-0.81874547], r_t = -0.06703441411488548, s_t+1 : [-0.37657465 -0.00962099].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 65\n",
      "\n",
      "\n",
      "a_t = [0.9282364], r_t = -0.08616228106138134, s_t+1 : [-0.38587055 -0.00929591].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 66\n",
      "\n",
      "\n",
      "a_t = [-0.14778298], r_t = -0.002183981014338425, s_t+1 : [-0.39639195 -0.0105214 ].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 67\n",
      "\n",
      "\n",
      "a_t = [0.16857258], r_t = -0.002841671474193017, s_t+1 : [-0.40759155 -0.0111996 ].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 68\n",
      "\n",
      "\n",
      "a_t = [0.08649135], r_t = -0.0007480754111371994, s_t+1 : [-0.41951402 -0.01192246].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 69\n",
      "\n",
      "\n",
      "a_t = [-0.86855362], r_t = -0.07543853871031359, s_t+1 : [-0.43350732 -0.01399331].\n",
      "[-10.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Finish at timestep 70\n",
      "\n",
      "\n",
      "a_t = [0.25710086], r_t = -0.006610085120119191, s_t+1 : [-0.44778247 -0.01427514].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 71\n",
      "\n",
      "\n",
      "a_t = [0.68039794], r_t = -0.046294135504673595, s_t+1 : [-0.46160074 -0.01381828].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 72\n",
      "\n",
      "\n",
      "a_t = [1.58079722], r_t = -0.24989198609741892, s_t+1 : [-0.47438133 -0.01278059].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 73\n",
      "\n",
      "\n",
      "a_t = [1.43857718], r_t = -0.20695042918155734, s_t+1 : [-0.48602971 -0.01164838].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 74\n",
      "\n",
      "\n",
      "a_t = [0.91854863], r_t = -0.08437315910474102, s_t+1 : [-0.49658144 -0.01055173].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 75\n",
      "\n",
      "\n",
      "a_t = [0.09032386], r_t = -0.000815839977611337, s_t+1 : [-0.50720009 -0.01061865].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 76\n",
      "\n",
      "\n",
      "a_t = [-0.19454085], r_t = -0.00378461417184626, s_t+1 : [-0.51823349 -0.0110334 ].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 77\n",
      "\n",
      "\n",
      "a_t = [0.56464807], r_t = -0.031882744321083824, s_t+1 : [-0.52846016 -0.01022667].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 78\n",
      "\n",
      "\n",
      "a_t = [0.35963141], r_t = -0.012933475174151943, s_t+1 : [-0.53811092 -0.00965076].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 79\n",
      "\n",
      "\n",
      "a_t = [-0.83876596], r_t = -0.0703528341744331, s_t+1 : [-0.54891102 -0.0108001 ].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 80\n",
      "\n",
      "\n",
      "a_t = [-0.36018428], r_t = -0.0129732717263445, s_t+1 : [-0.56006174 -0.01115072].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 81\n",
      "\n",
      "\n",
      "a_t = [-0.395621], r_t = -0.015651597730275246, s_t+1 : [-0.57153297 -0.01147122].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 82\n",
      "\n",
      "\n",
      "a_t = [0.78588247], r_t = -0.061761126450086204, s_t+1 : [-0.5814671  -0.00993413].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 83\n",
      "\n",
      "\n",
      "a_t = [-0.63081912], r_t = -0.039793275670153776, s_t+1 : [-0.59191563 -0.01044853].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 84\n",
      "\n",
      "\n",
      "a_t = [0.67216656], r_t = -0.04518078812342863, s_t+1 : [-0.60084711 -0.00893148].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 85\n",
      "\n",
      "\n",
      "a_t = [1.11559002], r_t = -0.12445411015030311, s_t+1 : [-0.60770439 -0.00685729].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 86\n",
      "\n",
      "\n",
      "a_t = [0.14339576], r_t = -0.002056234442496493, s_t+1 : [-0.61372247 -0.00601807].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 87\n",
      "\n",
      "\n",
      "a_t = [-0.38371832], r_t = -0.014723974862360975, s_t+1 : [-0.6196484  -0.00592593].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 88\n",
      "\n",
      "\n",
      "a_t = [-0.31222213], r_t = -0.009748265609874534, s_t+1 : [-0.62533222 -0.00568382].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 89\n",
      "\n",
      "\n",
      "a_t = [-1.25313087], r_t = -0.15703369810827794, s_t+1 : [-0.63176482 -0.00643261].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 90\n",
      "\n",
      "\n",
      "a_t = [-1.35401214], r_t = -0.18333488758025118, s_t+1 : [-0.63890035 -0.00713552].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 91\n",
      "\n",
      "\n",
      "a_t = [1.03586372], r_t = -0.10730136467398531, s_t+1 : [-0.64368825 -0.0047879 ].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 92\n",
      "\n",
      "\n",
      "a_t = [-1.37877886], r_t = -0.19010311402656913, s_t+1 : [-0.64909484 -0.00540659].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 93\n",
      "\n",
      "\n",
      "a_t = [0.15343455], r_t = -0.0023542161503342465, s_t+1 : [-0.65335214 -0.0042573 ].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 94\n",
      "\n",
      "\n",
      "a_t = [-0.23847846], r_t = -0.005687197416619449, s_t+1 : [-0.65701839 -0.00366625].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 95\n",
      "\n",
      "\n",
      "a_t = [-2.15210375], r_t = -0.4631550544841244, s_t+1 : [-0.66121051 -0.00419211].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 96\n",
      "\n",
      "\n",
      "a_t = [1.30397175], r_t = -0.17003423213417065, s_t+1 : [-0.6628996  -0.00168909].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 97\n",
      "\n",
      "\n",
      "a_t = [-0.62856914], r_t = -0.03950991622760331, s_t+1 : [-0.66451693 -0.00161734].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 98\n",
      "\n",
      "\n",
      "a_t = [-1.27022533], r_t = -0.1613472389506674, s_t+1 : [-0.66660858 -0.00209165].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 99\n",
      "\n",
      "\n",
      "a_t = [3.28835806], r_t = -1.081329875206148, s_t+1 : [-6.66160264e-01  4.48320338e-04].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 100\n",
      "\n",
      "\n",
      "a_t = [0.20428627], r_t = -0.0041732880348535045, s_t+1 : [-0.6643686   0.00179166].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 101\n",
      "\n",
      "\n",
      "a_t = [0.75188078], r_t = -0.05653247114708542, s_t+1 : [-0.66042445  0.00394415].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 102\n",
      "\n",
      "\n",
      "a_t = [-0.24071834], r_t = -0.00579453207620402, s_t+1 : [-0.65584376  0.00458069].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 103\n",
      "\n",
      "\n",
      "a_t = [0.25560103], r_t = -0.006533188562527674, s_t+1 : [-0.64991364  0.00593012].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 104\n",
      "\n",
      "\n",
      "a_t = [-0.69439781], r_t = -0.048218831159102034, s_t+1 : [-0.64410027  0.00581337].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 105\n",
      "\n",
      "\n",
      "a_t = [0.49071133], r_t = -0.024079760457484584, s_t+1 : [-0.63666663  0.00743364].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 106\n",
      "\n",
      "\n",
      "a_t = [1.43232602], r_t = -0.20515578389696498, s_t+1 : [-0.62690114  0.00976548].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 107\n",
      "\n",
      "\n",
      "a_t = [-1.36831502], r_t = -0.1872285990567042, s_t+1 : [-0.61787324  0.00902791].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 108\n",
      "\n",
      "\n",
      "a_t = [-0.91023561], r_t = -0.08285288594775098, s_t+1 : [-0.60951301  0.00836022].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 109\n",
      "\n",
      "\n",
      "a_t = [-0.10682394], r_t = -0.0011411354542834613, s_t+1 : [-0.60067578  0.00883723].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 110\n",
      "\n",
      "\n",
      "a_t = [-0.8879937], r_t = -0.07885328155742395, s_t+1 : [-0.59259759  0.00807818].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 111\n",
      "\n",
      "\n",
      "a_t = [-0.24001732], r_t = -0.005760831168150261, s_t+1 : [-0.58436563  0.00823196].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 112\n",
      "\n",
      "\n",
      "a_t = [1.90806693], r_t = -0.3640719412416679, s_t+1 : [-0.57418044  0.01018519].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 113\n",
      "\n",
      "\n",
      "a_t = [-0.01236723], r_t = -1.5294830231387914e-05, s_t+1 : [-0.56363589  0.01054455].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 114\n",
      "\n",
      "\n",
      "a_t = [0.24776382], r_t = -0.006138691059221589, s_t+1 : [-0.55242013  0.01121575].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 115\n",
      "\n",
      "\n",
      "a_t = [0.99229165], r_t = -0.09846427096878711, s_t+1 : [-0.53950005  0.01292008].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 116\n",
      "\n",
      "\n",
      "a_t = [-0.02719549], r_t = -7.395944646461964e-05, s_t+1 : [-0.52650155  0.0129985 ].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 117\n",
      "\n",
      "\n",
      "a_t = [0.73020948], r_t = -0.05332058798441385, s_t+1 : [-0.51238596  0.01411559].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 118\n",
      "\n",
      "\n",
      "a_t = [1.12738558], r_t = -0.12709982441829748, s_t+1 : [-0.49685446  0.01553151].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 119\n",
      "\n",
      "\n",
      "a_t = [-1.37197754], r_t = -0.1882322357353871, s_t+1 : [-0.48302332  0.01383114].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 120\n",
      "\n",
      "\n",
      "a_t = [-0.10162596], r_t = -0.0010327835603375446, s_t+1 : [-0.46964818  0.01337514].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 121\n",
      "\n",
      "\n",
      "a_t = [0.05697525], r_t = -0.0003246179320724328, s_t+1 : [-0.45659045  0.01305773].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 122\n",
      "\n",
      "\n",
      "a_t = [-0.28427433], r_t = -0.008081189649135642, s_t+1 : [-0.44445831  0.01213214].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 123\n",
      "\n",
      "\n",
      "a_t = [0.82888881], r_t = -0.06870566618677308, s_t+1 : [-0.43167083  0.01278748].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 124\n",
      "\n",
      "\n",
      "a_t = [-0.56899188], r_t = -0.03237517608118939, s_t+1 : [-0.4204176   0.01125324].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 125\n",
      "\n",
      "\n",
      "a_t = [0.17574429], r_t = -0.0030886055963057174, s_t+1 : [-0.4096623   0.01075529].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 126\n",
      "\n",
      "\n",
      "a_t = [-3.5177402], r_t = -1.237449614019994, s_t+1 : [-0.40124499  0.00841731].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 127\n",
      "\n",
      "\n",
      "a_t = [-0.0364025], r_t = -0.00013251418161931895, s_t+1 : [-0.39377947  0.00746552].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 128\n",
      "\n",
      "\n",
      "a_t = [0.67417576], r_t = -0.045451296106189774, s_t+1 : [-0.3862519   0.00752757].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 129\n",
      "\n",
      "\n",
      "a_t = [-0.23515171], r_t = -0.005529632536878423, s_t+1 : [-0.38007825  0.00617364].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 130\n",
      "\n",
      "\n",
      "a_t = [-1.52526079], r_t = -0.23264204668135144, s_t+1 : [-0.37644806  0.00363019].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 131\n",
      "\n",
      "\n",
      "a_t = [1.32978483], r_t = -0.17683276817232108, s_t+1 : [-0.37238601  0.00406206].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 132\n",
      "\n",
      "\n",
      "a_t = [2.19175477], r_t = -0.48037889657051425, s_t+1 : [-0.36791955  0.00446646].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 133\n",
      "\n",
      "\n",
      "a_t = [-0.20577793], r_t = -0.004234455691746535, s_t+1 : [-0.36488736  0.00303219].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 134\n",
      "\n",
      "\n",
      "a_t = [-0.67417637], r_t = -0.04545137741650601, s_t+1 : [-0.36401231  0.00087505].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 135\n",
      "\n",
      "\n",
      "a_t = [0.22950524], r_t = -0.005267265641721402, s_t+1 : [-3.63944692e-01  6.76156955e-05].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 136\n",
      "\n",
      "\n",
      "a_t = [0.54564448], r_t = -0.02977278983796996, s_t+1 : [-3.64210756e-01 -2.66063705e-04].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 137\n",
      "\n",
      "\n",
      "a_t = [-0.6391281], r_t = -0.040848472705563285, s_t+1 : [-0.36658589 -0.00237513].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 138\n",
      "\n",
      "\n",
      "a_t = [0.10035402], r_t = -0.0010070930056859, s_t+1 : [-0.36994502 -0.00335913].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 139\n",
      "\n",
      "\n",
      "a_t = [0.10523761], r_t = -0.0011074955500575121, s_t+1 : [-0.37425831 -0.0043133 ].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 140\n",
      "\n",
      "\n",
      "a_t = [1.21434019], r_t = -0.14746220862626264, s_t+1 : [-0.37815457 -0.00389625].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 141\n",
      "\n",
      "\n",
      "a_t = [0.89771337], r_t = -0.08058892922092487, s_t+1 : [-0.3817608  -0.00360623].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 142\n",
      "\n",
      "\n",
      "a_t = [-0.23590213], r_t = -0.005564981623229119, s_t+1 : [-0.38675285 -0.00499206].\n",
      "[-10.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Finish at timestep 143\n",
      "\n",
      "\n",
      "a_t = [-0.10722387], r_t = -0.001149695736592247, s_t+1 : [-0.3929035  -0.00615065].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 144\n",
      "\n",
      "\n",
      "a_t = [0.68767778], r_t = -0.047290072401930734, s_t+1 : [-0.39897793 -0.00607442].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 145\n",
      "\n",
      "\n",
      "a_t = [-0.02992406], r_t = -8.954494996000439e-05, s_t+1 : [-0.40601027 -0.00703234].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 146\n",
      "\n",
      "\n",
      "a_t = [0.70673447], r_t = -0.04994736152331393, s_t+1 : [-0.41284625 -0.00683598].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 147\n",
      "\n",
      "\n",
      "a_t = [-1.75292392], r_t = -0.3072742256874208, s_t+1 : [-0.42199767 -0.00915142].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 148\n",
      "\n",
      "\n",
      "a_t = [1.84599536], r_t = -0.34076988840856937, s_t+1 : [-0.43039936 -0.00840169].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 149\n",
      "\n",
      "\n",
      "a_t = [-0.07409812], r_t = -0.000549053131293469, s_t+1 : [-0.43960212 -0.00920276].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 150\n",
      "\n",
      "\n",
      "a_t = [0.14202204], r_t = -0.002017025953118596, s_t+1 : [-0.44921517 -0.00961305].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 151\n",
      "\n",
      "\n",
      "a_t = [0.44611359], r_t = -0.01990173357998812, s_t+1 : [-0.45871231 -0.00949714].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 152\n",
      "\n",
      "\n",
      "a_t = [-0.85784015], r_t = -0.0735889727352276, s_t+1 : [-0.4699798  -0.01126748].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 153\n",
      "\n",
      "\n",
      "a_t = [0.80817704], r_t = -0.0653150128612947, s_t+1 : [-0.48043542 -0.01045563].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 154\n",
      "\n",
      "\n",
      "a_t = [0.10453321], r_t = -0.001092719275920841, s_t+1 : [-0.49105707 -0.01062165].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 155\n",
      "\n",
      "\n",
      "a_t = [-0.45057556], r_t = -0.020301833912973008, s_t+1 : [-0.50259826 -0.01154119].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 156\n",
      "\n",
      "\n",
      "a_t = [1.22156238], r_t = -0.14922146555263568, s_t+1 : [-0.51279685 -0.01019859].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 157\n",
      "\n",
      "\n",
      "a_t = [-0.13605171], r_t = -0.0018510069095717886, s_t+1 : [-0.52328051 -0.01048367].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 158\n",
      "\n",
      "\n",
      "a_t = [0.50720859], r_t = -0.025726055698686336, s_t+1 : [-0.53300575 -0.00972524].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 159\n",
      "\n",
      "\n",
      "a_t = [-0.81924997], r_t = -0.06711705199171011, s_t+1 : [-0.54388933 -0.01088357].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 160\n",
      "\n",
      "\n",
      "a_t = [-0.32991189], r_t = -0.010884185709170088, s_t+1 : [-0.55511568 -0.01122635].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 161\n",
      "\n",
      "\n",
      "a_t = [-0.84453816], r_t = -0.07132447030860031, s_t+1 : [-0.56737282 -0.01225714].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 162\n",
      "\n",
      "\n",
      "a_t = [-0.93631667], r_t = -0.08766888998044435, s_t+1 : [-0.58070707 -0.01333425].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 163\n",
      "\n",
      "\n",
      "a_t = [-1.54183052], r_t = -0.23772413399150294, s_t+1 : [-0.5951151  -0.01440803].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 164\n",
      "\n",
      "\n",
      "a_t = [0.14903653], r_t = -0.0022211886228324556, s_t+1 : [-0.6087673  -0.01365221].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 165\n",
      "\n",
      "\n",
      "a_t = [1.06684343], r_t = -0.1138154908616072, s_t+1 : [-0.62028767 -0.01152037].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 166\n",
      "\n",
      "\n",
      "a_t = [-0.4761333], r_t = -0.02267029210128708, s_t+1 : [-0.63180721 -0.01151953].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 167\n",
      "\n",
      "\n",
      "a_t = [-0.77695251], r_t = -0.06036551987488238, s_t+1 : [-0.64369478 -0.01188758].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 168\n",
      "\n",
      "\n",
      "a_t = [0.33012354], r_t = -0.010898154968684286, s_t+1 : [-0.65420581 -0.01051103].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 169\n",
      "\n",
      "\n",
      "a_t = [-1.21174874], r_t = -0.14683349978959903, s_t+1 : [-0.66526216 -0.01105635].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 170\n",
      "\n",
      "\n",
      "a_t = [1.99888066], r_t = -0.3995523888020325, s_t+1 : [-0.67378773 -0.00852557].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 171\n",
      "\n",
      "\n",
      "a_t = [-1.83589899], r_t = -0.33705251189339336, s_t+1 : [-0.68272461 -0.00893688].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 172\n",
      "\n",
      "\n",
      "a_t = [0.23106143], r_t = -0.005338938276356009, s_t+1 : [-0.69016627 -0.00744166].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 173\n",
      "\n",
      "\n",
      "a_t = [-0.5096292], r_t = -0.02597219264505305, s_t+1 : [-0.69717447 -0.00700819].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 174\n",
      "\n",
      "\n",
      "a_t = [0.6872879], r_t = -0.047236465685673024, s_t+1 : [-0.70190795 -0.00473348].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 175\n",
      "\n",
      "\n",
      "a_t = [0.82750769], r_t = -0.06847689769567099, s_t+1 : [-0.70412573 -0.00221778].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 176\n",
      "\n",
      "\n",
      "a_t = [1.50551777], r_t = -0.2266583770174443, s_t+1 : [-7.03554774e-01  5.70952721e-04].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 177\n",
      "\n",
      "\n",
      "a_t = [-0.18310447], r_t = -0.003352724530821358, s_t+1 : [-0.70197342  0.00158135].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 178\n",
      "\n",
      "\n",
      "a_t = [0.25033341], r_t = -0.0062666814300341225, s_t+1 : [-0.6987417   0.00323172].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 179\n",
      "\n",
      "\n",
      "a_t = [0.29765462], r_t = -0.008859827280826604, s_t+1 : [-0.69380953  0.00493216].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 180\n",
      "\n",
      "\n",
      "a_t = [2.2710437], r_t = -0.5157639493258812, s_t+1 : [-0.68615555  0.00765399].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 181\n",
      "\n",
      "\n",
      "a_t = [1.34111576], r_t = -0.17985914795114533, s_t+1 : [-0.67583014  0.01032541].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 182\n",
      "\n",
      "\n",
      "a_t = [-0.72947335], r_t = -0.05321313625640294, s_t+1 : [-0.66549648  0.01033366].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 183\n",
      "\n",
      "\n",
      "a_t = [-0.65926325], r_t = -0.04346280357405036, s_t+1 : [-0.65511934  0.01037714].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 184\n",
      "\n",
      "\n",
      "a_t = [-0.95648715], r_t = -0.09148676665424504, s_t+1 : [-0.64521592  0.00990342].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 185\n",
      "\n",
      "\n",
      "a_t = [-0.09280542], r_t = -0.0008612846126092243, s_t+1 : [-0.63455968  0.01065624].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 186\n",
      "\n",
      "\n",
      "a_t = [-0.46864168], r_t = -0.021962502637745254, s_t+1 : [-0.62378948  0.0107702 ].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 187\n",
      "\n",
      "\n",
      "a_t = [0.62933429], r_t = -0.0396061650258997, s_t+1 : [-0.61133511  0.01245437].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 188\n",
      "\n",
      "\n",
      "a_t = [1.50521508], r_t = -0.22656724472340853, s_t+1 : [-0.59673029  0.01460482].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 189\n",
      "\n",
      "\n",
      "a_t = [0.97020598], r_t = -0.09412996440860683, s_t+1 : [-0.58012607  0.01660422].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 190\n",
      "\n",
      "\n",
      "a_t = [-0.19377183], r_t = -0.0037547523020939376, s_t+1 : [-0.56339058  0.01673549].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 191\n",
      "\n",
      "\n",
      "a_t = [-0.19170537], r_t = -0.0036750948409881795, s_t+1 : [-0.54664491  0.01674566].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 192\n",
      "\n",
      "\n",
      "a_t = [-0.4335687], r_t = -0.01879818213928822, s_t+1 : [-0.53037689  0.01626802].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 193\n",
      "\n",
      "\n",
      "a_t = [0.67059944], r_t = -0.04497036082542643, s_t+1 : [-0.51305214  0.01732475].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 194\n",
      "\n",
      "\n",
      "a_t = [0.25357608], r_t = -0.0064300830516037175, s_t+1 : [-0.49542611  0.01762603].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 195\n",
      "\n",
      "\n",
      "a_t = [0.63961867], r_t = -0.04091120377657986, s_t+1 : [-0.4770517   0.01837441].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 196\n",
      "\n",
      "\n",
      "a_t = [0.08883617], r_t = -0.0007891865359456589, s_t+1 : [-0.458892   0.0181597].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 197\n",
      "\n",
      "\n",
      "a_t = [0.59976483], r_t = -0.03597178514284947, s_t+1 : [-0.44031492  0.01857709].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 198\n",
      "\n",
      "\n",
      "a_t = [-0.75439073], r_t = -0.05691053696169527, s_t+1 : [-0.42348757  0.01682735].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 199\n",
      "\n",
      "\n",
      "a_t = [0.67217826], r_t = -0.04518236169874571, s_t+1 : [-0.40639155  0.01709602].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 200\n",
      "\n",
      "\n",
      "a_t = [0.99997521], r_t = -0.09999504238690793, s_t+1 : [-0.38865662  0.01773493].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 201\n",
      "\n",
      "\n",
      "a_t = [1.62812893], r_t = -0.26508038194728395, s_t+1 : [-0.37040633  0.01825028].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 202\n",
      "\n",
      "\n",
      "a_t = [-0.17987837], r_t = -0.0032356226607570962, s_t+1 : [-0.35353479  0.01687154].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 203\n",
      "\n",
      "\n",
      "a_t = [1.51822459], r_t = -0.23050059169758794, s_t+1 : [-0.33638411  0.01715068].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 204\n",
      "\n",
      "\n",
      "a_t = [1.21794903], r_t = -0.14833998382586874, s_t+1 : [-0.31906488  0.01731923].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 205\n",
      "\n",
      "\n",
      "a_t = [-0.92546897], r_t = -0.08564928063650504, s_t+1 : [-0.30457339  0.01449149].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 206\n",
      "\n",
      "\n",
      "a_t = [-0.35860382], r_t = -0.012859670215904052, s_t+1 : [-0.29214681  0.01242657].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 207\n",
      "\n",
      "\n",
      "a_t = [-0.42720879], r_t = -0.01825073534061711, s_t+1 : [-0.28196078  0.01018603].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 208\n",
      "\n",
      "\n",
      "a_t = [0.82893553], r_t = -0.06871341132092205, s_t+1 : [-0.27218902  0.00977176].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 209\n",
      "\n",
      "\n",
      "a_t = [-0.19701018], r_t = -0.0038813012368955077, s_t+1 : [-0.26442459  0.00776443].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 210\n",
      "\n",
      "\n",
      "a_t = [0.89917592], r_t = -0.08085173297637505, s_t+1 : [-0.25706519  0.0073594 ].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 211\n",
      "\n",
      "\n",
      "a_t = [-0.72902808], r_t = -0.05314819472996682, s_t+1 : [-0.25259203  0.00447316].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 212\n",
      "\n",
      "\n",
      "a_t = [-0.04271335], r_t = -0.000182443008528273, s_t+1 : [-0.24999885  0.00259318].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 213\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "a_t = [0.63619663], r_t = -0.040474614981045896, s_t+1 : [-0.2482806   0.00171825].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 214\n",
      "\n",
      "\n",
      "a_t = [-0.17305948], r_t = -0.002994958396022985, s_t+1 : [-0.24865994 -0.00037933].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 215\n",
      "\n",
      "\n",
      "a_t = [2.05678757], r_t = -0.4230375104704318, s_t+1 : [-0.24937533 -0.00071539].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 216\n",
      "\n",
      "\n",
      "a_t = [-1.18770384], r_t = -0.14106404090977356, s_t+1 : [-0.25342313 -0.0040478 ].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 217\n",
      "\n",
      "\n",
      "a_t = [-0.0557465], r_t = -0.00031076724814161293, s_t+1 : [-0.25936618 -0.00594305].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 218\n",
      "\n",
      "\n",
      "a_t = [-0.02698723], r_t = -7.283103227310888e-05, s_t+1 : [-0.26713033 -0.00776415].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 219\n",
      "\n",
      "\n",
      "a_t = [0.86313477], r_t = -0.07450016345278497, s_t+1 : [-0.27533905 -0.00820872].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 220\n",
      "\n",
      "\n",
      "a_t = [-0.80562989], r_t = -0.06490395201751181, s_t+1 : [-0.28645074 -0.01111169].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 221\n",
      "\n",
      "\n",
      "a_t = [0.38394661], r_t = -0.014741500030566526, s_t+1 : [-0.29861883 -0.01216809].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 222\n",
      "\n",
      "\n",
      "a_t = [0.41042447], r_t = -0.016844824359216123, s_t+1 : [-0.31173341 -0.01311458].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 223\n",
      "\n",
      "\n",
      "a_t = [-1.34127887], r_t = -0.17990290136326081, s_t+1 : [-0.32783214 -0.01609872].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 224\n",
      "\n",
      "\n",
      "a_t = [1.06847668], r_t = -0.11416424176262828, s_t+1 : [-0.34381615 -0.01598401].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 225\n",
      "\n",
      "\n",
      "a_t = [0.30891606], r_t = -0.00954291316780422, s_t+1 : [-0.36062073 -0.01680458].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 226\n",
      "\n",
      "\n",
      "a_t = [0.25581513], r_t = -0.00654413817508561, s_t+1 : [-0.37821579 -0.01759507].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 227\n",
      "\n",
      "\n",
      "a_t = [-0.36941241], r_t = -0.013646552712822689, s_t+1 : [-0.39742111 -0.01920532].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 228\n",
      "\n",
      "\n",
      "a_t = [0.38223998], r_t = -0.014610740277747891, s_t+1 : [-0.41697696 -0.01955585].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 229\n",
      "\n",
      "\n",
      "a_t = [0.02235908], r_t = -4.99928235306908e-05, s_t+1 : [-0.43728537 -0.02030841].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 230\n",
      "\n",
      "\n",
      "a_t = [1.56849861], r_t = -0.24601878879205166, s_t+1 : [-0.45673393 -0.01944855].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 231\n",
      "\n",
      "\n",
      "a_t = [1.04778748], r_t = -0.10978586007980028, s_t+1 : [-0.47518061 -0.01844668].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 232\n",
      "\n",
      "\n",
      "a_t = [-0.7270902], r_t = -0.05286601630761977, s_t+1 : [-0.49507978 -0.01989918].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 233\n",
      "\n",
      "\n",
      "a_t = [1.96636239], r_t = -0.38665810682663104, s_t+1 : [-0.51369259 -0.01861281].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 234\n",
      "\n",
      "\n",
      "a_t = [0.64943937], r_t = -0.04217714945220277, s_t+1 : [-0.53140553 -0.01771294].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 235\n",
      "\n",
      "\n",
      "a_t = [-0.06433356], r_t = -0.0004138806965788117, s_t+1 : [-0.54915642 -0.01775089].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 236\n",
      "\n",
      "\n",
      "a_t = [-0.11810632], r_t = -0.001394910330617177, s_t+1 : [-0.56689297 -0.01773656].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 237\n",
      "\n",
      "\n",
      "a_t = [-1.15591575], r_t = -0.13361412123752503, s_t+1 : [-0.58580573 -0.01891276].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 238\n",
      "\n",
      "\n",
      "a_t = [-0.20827639], r_t = -0.004337905348109526, s_t+1 : [-0.60456706 -0.01876133].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 239\n",
      "\n",
      "\n",
      "a_t = [-0.05147998], r_t = -0.0002650188123535063, s_t+1 : [-0.6228043  -0.01823724].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 240\n",
      "\n",
      "\n",
      "a_t = [-1.05833122], r_t = -0.1120064968410093, s_t+1 : [-0.64180843 -0.01900413].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 241\n",
      "\n",
      "\n",
      "a_t = [0.41053467], r_t = -0.01685387136520066, s_t+1 : [-0.65932866 -0.01752022].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 242\n",
      "\n",
      "\n",
      "a_t = [1.47668927], r_t = -0.21806111967806563, s_t+1 : [-0.6743588  -0.01503015].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 243\n",
      "\n",
      "\n",
      "a_t = [-0.69091605], r_t = -0.04773649824069121, s_t+1 : [-0.68933278 -0.01497398].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 244\n",
      "\n",
      "\n",
      "a_t = [-1.17806458], r_t = -0.13878361477254758, s_t+1 : [-0.70461434 -0.01528156].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 245\n",
      "\n",
      "\n",
      "a_t = [1.21059677], r_t = -0.1465544544964241, s_t+1 : [-0.71710403 -0.01248969].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 246\n",
      "\n",
      "\n",
      "a_t = [3.41906922], r_t = -1.1690034365217827, s_t+1 : [-0.72672259 -0.00961855].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 247\n",
      "\n",
      "\n",
      "a_t = [1.86700888], r_t = -0.34857221732184474, s_t+1 : [-0.73341026 -0.00668767].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 248\n",
      "\n",
      "\n",
      "a_t = [-0.45833379], r_t = -0.021006986687627807, s_t+1 : [-0.73931371 -0.00590345].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 249\n",
      "\n",
      "\n",
      "a_t = [-1.0913636], r_t = -0.11910745171288205, s_t+1 : [-0.74520989 -0.00589618].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 250\n",
      "\n",
      "\n",
      "a_t = [0.47784013], r_t = -0.022833118822169974, s_t+1 : [-0.74884699 -0.0036371 ].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 251\n",
      "\n",
      "\n",
      "a_t = [-3.26663294], r_t = -1.0670890748963886, s_t+1 : [-0.75242039 -0.0035734 ].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 252\n",
      "\n",
      "\n",
      "a_t = [0.46373013], r_t = -0.021504563083898996, s_t+1 : [-0.75371368 -0.00129329].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 253\n",
      "\n",
      "\n",
      "a_t = [-0.02010903], r_t = -4.043731484723138e-05, s_t+1 : [-7.53445121e-01  2.68555423e-04].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 254\n",
      "\n",
      "\n",
      "a_t = [0.23877307], r_t = -0.005701257994934341, s_t+1 : [-0.75122795  0.00221717].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 255\n",
      "\n",
      "\n",
      "a_t = [0.38355987], r_t = -0.01471181716303954, s_t+1 : [-0.74685785  0.0043701 ].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 256\n",
      "\n",
      "\n",
      "a_t = [2.56123768], r_t = -0.6559938456564068, s_t+1 : [-0.73943573  0.00742213].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 257\n",
      "\n",
      "\n",
      "a_t = [-0.29738752], r_t = -0.008843933496566892, s_t+1 : [-0.73095167  0.00848405].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 258\n",
      "\n",
      "\n",
      "a_t = [-0.0007513], r_t = -5.644508416073755e-08, s_t+1 : [-0.72101198  0.0099397 ].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 259\n",
      "\n",
      "\n",
      "a_t = [0.67670926], r_t = -0.04579354264116923, s_t+1 : [-0.70866166  0.01235031].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 260\n",
      "\n",
      "\n",
      "a_t = [-0.68071919], r_t = -0.04633786146126708, s_t+1 : [-0.69601467  0.01264699].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 261\n",
      "\n",
      "\n",
      "a_t = [0.28730021], r_t = -0.008254140851740971, s_t+1 : [-0.6817005   0.01431417].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 262\n",
      "\n",
      "\n",
      "a_t = [-0.46501264], r_t = -0.021623675939149118, s_t+1 : [-0.66694204  0.01475845].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 263\n",
      "\n",
      "\n",
      "a_t = [0.94084349], r_t = -0.08851864763580766, s_t+1 : [-0.64973008  0.01721196].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 264\n",
      "\n",
      "\n",
      "a_t = [-0.36544239], r_t = -0.013354813729823526, s_t+1 : [-0.63214271  0.01758737].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 265\n",
      "\n",
      "\n",
      "a_t = [0.16484856], r_t = -0.002717504818634817, s_t+1 : [-0.6135083   0.01863441].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 266\n",
      "\n",
      "\n",
      "a_t = [-0.38193805], r_t = -0.014587667719018857, s_t+1 : [-0.59478062  0.01872768].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 267\n",
      "\n",
      "\n",
      "a_t = [-0.22223624], r_t = -0.004938894635093537, s_t+1 : [-0.57585649  0.01892414].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 268\n",
      "\n",
      "\n",
      "a_t = [-1.34117792], r_t = -0.17987582260223356, s_t+1 : [-0.55804202  0.01781447].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 269\n",
      "\n",
      "\n",
      "a_t = [0.84489865], r_t = -0.07138537204632393, s_t+1 : [-0.53870233  0.01933968].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 270\n",
      "\n",
      "\n",
      "a_t = [0.38972676], r_t = -0.015188694694352599, s_t+1 : [-0.51866483  0.02003751].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 271\n",
      "\n",
      "\n",
      "a_t = [0.03222203], r_t = -0.00010382590537049357, s_t+1 : [-0.49861599  0.02004884].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 272\n",
      "\n",
      "\n",
      "a_t = [0.13076794], r_t = -0.0017100255198984296, s_t+1 : [-0.47855819  0.0200578 ].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 273\n",
      "\n",
      "\n",
      "a_t = [0.0567147], r_t = -0.0003216556996964207, s_t+1 : [-0.4587521   0.01980609].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 274\n",
      "\n",
      "\n",
      "a_t = [-1.01048126], r_t = -0.1021072382631416, s_t+1 : [-0.4409293  0.0178228].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 275\n",
      "\n",
      "\n",
      "a_t = [0.02332219], r_t = -5.439245611895622e-05, s_t+1 : [-0.4236852  0.0172441].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 276\n",
      "\n",
      "\n",
      "a_t = [-0.04093058], r_t = -0.0001675312087651083, s_t+1 : [-0.40724067  0.01644452].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 277\n",
      "\n",
      "\n",
      "a_t = [1.69627088], r_t = -0.28773349117617436, s_t+1 : [-0.39015122  0.01708945].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 278\n",
      "\n",
      "\n",
      "a_t = [-0.82906408], r_t = -0.06873472491264554, s_t+1 : [-0.3752797   0.01487152].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 279\n",
      "\n",
      "\n",
      "a_t = [-0.00229415], r_t = -5.263115443948336e-07, s_t+1 : [-0.36148766  0.01379203].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 280\n",
      "\n",
      "\n",
      "a_t = [-1.09541191], r_t = -0.11999272480875722, s_t+1 : [-0.3503641   0.01112356].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 281\n",
      "\n",
      "\n",
      "a_t = [-0.30906932], r_t = -0.009552384728171713, s_t+1 : [-0.3409457  0.0094184].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 282\n",
      "\n",
      "\n",
      "a_t = [-0.83119613], r_t = -0.06908870073724031, s_t+1 : [-0.33407645  0.00686924].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 283\n",
      "\n",
      "\n",
      "a_t = [-0.54700908], r_t = -0.029921893134186202, s_t+1 : [-0.32937379  0.00470267].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 284\n",
      "\n",
      "\n",
      "a_t = [-0.48700582], r_t = -0.02371746720975325, s_t+1 : [-0.32677728  0.00259651].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 285\n",
      "\n",
      "\n",
      "a_t = [-2.65912442], r_t = -0.7070942697797834, s_t+1 : [-3.27072637e-01 -2.95358657e-04].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 286\n",
      "\n",
      "\n",
      "a_t = [1.07838605], r_t = -0.11629164805748558, s_t+1 : [-3.27258022e-01 -1.85385313e-04].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 287\n",
      "\n",
      "\n",
      "a_t = [-0.58313596], r_t = -0.03400475476558431, s_t+1 : [-0.32970698 -0.00244896].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 288\n",
      "\n",
      "\n",
      "a_t = [-1.05618591], r_t = -0.11155286746344094, s_t+1 : [-0.3350295  -0.00532252].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 289\n",
      "\n",
      "\n",
      "a_t = [0.86833422], r_t = -0.07540043148893462, s_t+1 : [-0.34038956 -0.00536005].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 290\n",
      "\n",
      "\n",
      "a_t = [0.72104352], r_t = -0.051990376068152155, s_t+1 : [-0.34597397 -0.00558441].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 291\n",
      "\n",
      "\n",
      "a_t = [0.63805066], r_t = -0.04071086410627877, s_t+1 : [-0.35187134 -0.00589737].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 292\n",
      "\n",
      "\n",
      "a_t = [0.79457582], r_t = -0.06313507373129577, s_t+1 : [-0.35780857 -0.00593724].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 293\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "a_t = [-0.14344175], r_t = -0.0020575536839780154, s_t+1 : [-0.36515376 -0.00734519].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 294\n",
      "\n",
      "\n",
      "a_t = [0.50706163], r_t = -0.02571114978810173, s_t+1 : [-0.37288245 -0.00772869].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 295\n",
      "\n",
      "\n",
      "a_t = [1.3436626], r_t = -0.18054291864643568, s_t+1 : [-0.38020338 -0.00732094].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 296\n",
      "\n",
      "\n",
      "a_t = [-0.00908635], r_t = -8.256173119731058e-06, s_t+1 : [-0.38858055 -0.00837717].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 297\n",
      "\n",
      "\n",
      "a_t = [-0.92735263], r_t = -0.08599828989402795, s_t+1 : [-0.39933392 -0.01075337].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 298\n",
      "\n",
      "\n",
      "a_t = [0.48089229], r_t = -0.02312573965486449, s_t+1 : [-0.41027649 -0.01094258].\n",
      "[-10.]\n",
      "\n",
      "\n",
      "Finish at timestep 299\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in range(300):\n",
    "    a = np.random.randn(1)\n",
    "    s, r, _, done = env.step(a)\n",
    "    print(f\"a_t = {a}, r_t = {r}, s_t+1 : {s}.\")\n",
    "    print(f\"{a**2 / r }\")\n",
    "    env.render()\n",
    "    if done:\n",
    "        print(f\"\\n\\nFinish at timestep {t}\\n\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Rewards are continuous. r = a^2 / 10. And -10. for an illegal finish.\n",
    "- If the speed is too high, it finishes?\n",
    "- We receive a reward of 100 for finishing successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A3CAgent():\n",
    "    \n",
    "    def __init__(self, env, num_agents = 1, track_Q = False, learning_rate = 0.001):\n",
    "        \n",
    "        # Hyperparameters for the algorithm:\n",
    "        self.num_agents = num_agents            # The number of paralell agents that the algorithm manages.\n",
    "        self.epsilon = [.9] * num_agents        # Exploration rate. \n",
    "        self.epsilon_decay = [.95] * num_agents # Decay of the exploration rate, multiplied with epsilon every training episode.\n",
    "        self.epsilon_min = [.1] * num_agents    # Minimal exploration rate.\n",
    "        self.lr = learning_rate                 # Learning Rate.\n",
    "        self.gamma = .99                        # The discounting factor of the Markov Decision Process.\n",
    "    \n",
    "        # Environment specification:\n",
    "        self.env = env\n",
    "        self.num_actions = env.action_space.shape[0]\n",
    "        self.num_state_dim = env.observation_space.shape[0]\n",
    "        \n",
    "        # Q-Network and Policy Network specifications - 2 hidden layers with relu followed by, for the\n",
    "        #                                               Value network (\"The Critic\"): a linear layer\n",
    "        #                                               Policy Network (\"The Actor\"): a linear layer\n",
    "        self.num_nodes_layer1 = 24          # The number of nodes in the first hidden layer of the network.\n",
    "        self.num_nodes_layer2 = 48          # The number of nodes in the second hidden layer of the network.\n",
    "        self.model = self.init_model()\n",
    "        self.target_model = self.init_model() # Fixed targets for the network updates.\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "         \n",
    "        # Metrics to evaluate the agent - TODO\n",
    "        self.training_epis = [0] * num_agents         # Number of training iterations so far.\n",
    "        self.num_steps = [[] for i in range(num_agents)]                 # Number of time steps needed to complete the episode, for each episode.\n",
    "        self.values = []                    # Total reward acrued for every episode.\n",
    "        self.max_X_list = []                # A list keeping track of the maximal x position in every training episode.\n",
    "        self.track_Q = track_Q              # A boolean indicating whether the agent keeps track of the Q-values at 2 states over all episodes.\n",
    "        self.xstart_vpos = [[],[],[]]       # List of Q-estimates in x = -0.5 (start position) and v = 0.01 over the training iterations.\n",
    "        self.xstart_vneg = [[],[],[]]       # List of Q-estimates in x = -0.5 (start position) and v = -0.01 over the training iterations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
